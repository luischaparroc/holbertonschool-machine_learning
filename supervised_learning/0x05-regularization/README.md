# Regularization

Project done during **Software Engineering studies** at **Holberton School**. It aims to learn about regularization (L1 and L2), dropout, early stopping, data augmentation.

## Technologies
* Python Scripts are written with Python 3.5
* `Tensorflow`, version 1.12
* `NumPy`, version 1.15

## Files
All of the following files are scripts and programs written in Python:

| Filename | Description |
| -------- | ----------- |
| `0-l2_reg_cost.py` | Function `l2_reg_cost` that calculates the cost of a neural network with L2 regularization |
| `1-l2_reg_gradient_descent.py` | Function `l2_reg_gradient_descent` that updates the weights and biases of a neural network using gradient descent with L2 regularization |
| `2-l2_reg_cost.py ` | Function `l2_reg_cost` that calculates the cost of a neural network with L2 regularization |
| `3-l2_reg_create_layer.py` | Function `l2_reg_create_layer` that creates a tensorflow layer that includes L2 regularization |
| `4-dropout_forward_prop.py` | Function `dropout_forward_prop` that conducts forward propagation using Dropout |
