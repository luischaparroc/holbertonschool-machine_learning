# Optimization

Project done during **Software Engineering studies** at **Holberton School**. It aims to learn hypermarameters, saddle points, normalizing data, stochastic gradient descent, mini-batch gradient descent, moving average, RMSProp, Adam optimization, learning rate decay and batch normalization.

## Technologies
* Python Scripts are written with Python 3.5
* `Tensorflow`, version 1.12
* `NumPy`, version 1.15

## Files
All of the following files are scripts and programs written in Python:

| Filename | Description |
| -------- | ----------- |
| `0-norm_constants.py` | Function `normalization_constants` that calculates the normalization (standardization) constant of a matrix |
| `1-normalize.py` | Function `normalize` that normalizes (standardizes) a matrix |
| `2-shuffle_data.py` | Function `suffle_data` that shuffles the data points in two matrices the same way |
